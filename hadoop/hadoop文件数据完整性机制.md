### Hadoop数据完整性机制

#####问题一：Hadoop如何检测数据是否损坏？
>
>
答：
>
1. 数据在第一次引入系统时计算校验和，并在数据通过一次不可靠传输时再次计算校验和。如果计算得到的校验和与原来的校验和不匹配，则判断数据已经损坏。
>
2. Hadoop会对写入的所有数据计算校验和，并在读取数据时验证校验和。默认情况下每io.bytes.per.checksum个字节数据计算一个校验和。
datanode在收到客户端的数据或者复制其他datanode数据时，会验证待存储数据的校验和。
>
3. 正在写数据的客户端将数据及其校验和发送到一系列datanode组成的管线，由管线中最后一个datanode负责验证校验和。如果校验出错误，则会给客户端返回一个ChecksumException
>
>4. 客户端从datanode读取数据时，也会计算校验和，将它们与datanode中存储的校验和进行比较。
>
>5. 每个datanode都会保持一个用于验证的校验和日志，每次客户端成功验证一个数据块后，会告诉datanode更新日志
>
>6. 每个datanode会定期运行DataBlockScanner定期验证存储在这datanode上所有的数据块
>


#### 问题二：检测到数据块损坏，Hadoop如何恢复数据？
>答：
>
>1. 客户端读取数据块时，检测到数据块损坏，则向namenode报告已损坏的数据块以及正在操作的datanode，再抛出ChecksumException，
>
>2. namenode将数据块的副本标记为已损坏。至此之后namenode将不再将处理请求发送到这个节点）
>
>3. 安排这个数据块的一个副本复制到另一个datanode（恢复副本冗余系数）
>
>4. 删除已经损坏的数据块副本


#### 问题三： 如何定位副本（Replica）
>
>答：
>namenode中维护着每个数据块所在的节点的信息，当客户端请求文件时，namenode就从内存中读取每个数据块最佳的datanode，将datanode列表告知客户端，然后客户端依次与这些最佳的datanode直接连接，读取数据块
>



#### 问题四：Hadoop数据副本如何存放？需要考虑哪些问题？
>
>答：
>namenode在选择哪儿个datanode存储副本时主要需要考虑：可靠性、写入带宽、读取带宽。
>
>如果将所有副本放在同一个节点：可靠性最差、写入带宽最大、读取带宽最大
>
>如果将所有副本放在不同的数据中心：可靠性最高、写入带宽最小、读取带宽最小
>
>Hadoop默认的副本分布策略：客户端节点放置第1个副本（考虑到客户端可能会有大的概率对数据进行读写，如果客户端在集群之外，则由系统随机选择服务相对空闲的节点进行存储）。第2个副本放在与第1个节点不同且随机另外选择的机架中节点上。第3个副本与第2个副本放在同一个机架上，且随机选择的另一个节点。其他副本放在集群中随机选择的节点上。
>
>
>
